= Logback and Log4j2 JSON layout (ECS compatible)
:toc:
:toclevels: 3
:toc-placement!:

toc::[]

Provides http://logback.qos.ch/[Logback] & https://logging.apache.org/log4j/2.x/[Log4j2] layouts to log in https://www.json.org/json-en.html[JSON] format following https://www.elastic.co/guide/en/ecs/current/ecs-reference.html[ECS] specification.

This library leverages the https://github.com/elastic/ecs-logging-java[`ecs-logging-java`] core library powered by Elastic.

NOTE: log4j framework being outdated, its support has been removed.

== Get started

=== Add the dependency

Gradle style:

[source,js]
----
compile ("org.talend.daikon:logging-event-layout:LATEST")
----

Maven style:

[source,xml]
----
<dependency>
  	<groupId>org.talend.daikon</groupId>
  	<artifactId>logging-event-layout</artifactId>
  	<version>LATEST</version>
</dependency>
----

=== Use the ECS layout

To log using JSON format following ECS specification, you must configure logback or log4j2 to use the provided layouts.

These layouts can generally be used by any logback and log4j2 appender.

==== Logback configuration

.logback.xml
[source,xml]
----
<configuration>
    <appender name="Console" class="ch.qos.logback.core.ConsoleAppender">
        <layout class="org.talend.daikon.logging.event.layout.LogbackJSONLayout">
            <serviceName>logging-sample</serviceName>
            <locationInfo>true</locationInfo>
            <hostInfo>true</hostInfo>
            <additionalField>
                <key>labels.my_custom_label</key>
                <value>Custom value</value>
            </additionalField>
        </layout>
    </appender>
    <root level="INFO">
        <appender-ref ref="Console" />
    </root>
</configuration>
----

===== Parameters

[width="80%",cols="3,2,2,10",options="header"]
|===
| Name           | Type    | Default | Description
| `serviceName`  | String  |         | Sets the `service.name` ECS field.
| `locationInfo` | boolean | `false` | If `true`, includes the `log.origin.file.name`, `log.origin.file.line` and `log.origin.function` ECS fields.
| `hostInfo`     | boolean | `true`  | If `true`, includes the `host.ip` and `host.hostname` ECS fields.
| `addEventUuid` | boolean | `true`  | If `true`, includes the `event.id` ECS field.
|===

===== Additional fields

To include any custom field in the output, use the following syntax :

[source,xml]
----
<layout class="org.talend.daikon.logging.event.layout.LogbackJSONLayout">
    <additionalField>
        <key>key1</key>
        <value>value1</value>
    </additionalField>
    <additionalField>
        <key>key2</key>
        <value>value2</value>
    </additionalField>
</layout>
----

==== Log4j2 configuration

.log4j2.xml
[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<configuration status="INFO" packages="org.talend.daikon.logging.event.layout" verbose="false">
    <appenders>
        <Console name="Console" target="SYSTEM_OUT">
            <Log4j2ECSLayout serviceName="logging-sample" locationInfo="true" hostInfo="true">
                <KeyValuePair key="labels.my_custom_label" value="Custom value"/>
            </Log4j2ECSLayout>
        </Console>
    </appenders>
    <loggers>
        <root level="INFO">
            <appender-ref ref="Console"/>
        </root>
    </loggers>
</configuration>
----

===== Parameters

[width="80%",cols="3,2,2,10",options="header"]
|===
| Name           | Type    | Default | Description
| `serviceName`  | String  |         | Sets the `service.name` ECS field.
| `locationInfo` | boolean | `false` | If `true`, includes the `log.origin.file.name`, `log.origin.file.line` and `log.origin.function` ECS fields.
| `hostInfo`     | boolean | `true`  | If `true`, includes the `host.ip` and `host.hostname` ECS fields.
| `addEventUuid` | boolean | `true`  | If `true`, includes the `event.id` ECS field.
|===

===== Additional fields

To include any custom field in the output, use the following syntax :

[source,xml]
----
<Log4j2ECSLayout>
    <KeyValuePair key="key1" value="value1"/>
    <KeyValuePair key="key2" value="value2"/>
</Log4j2ECSLayout>
----

== ECS fields

In order to ensure that the generated logs respect the ECS specification. The file https://github.com/elastic/ecs/blob/master/generated/ecs/ecs_flat.yml[`ecs_flat.yml`] is leveraged. This file is provided by Elastic and is linked to a specific version of ECS.

=== ECS version

The version of ECS used by this current library is referenced in the property file link:src/main/resources/logging.properties[`logging.properties`] :

.logging.properties
[source,properties]
----
include::src/main/resources/logging.properties[]
----

This value is used :

* By maven, during the `INITIALIZE` phase, in order to pull the corresponding https://github.com/elastic/ecs/blob/master/generated/ecs/ecs_flat.yml[`ecs_flat.yml`] file.
* By the library, by injecting the version into the generated logs.

=== ECS fields enum generation

ECS fields reference are well described in the https://www.elastic.co/guide/en/ecs/current/ecs-field-reference.html[Elastic documentation].

In order to help the developer to look for an ECS field, or even to provide a way for the current lib to filter out non ECS fields, the file https://github.com/elastic/ecs/blob/master/generated/ecs/ecs_flat.yml[`ecs_flat.yml` provided by Elastic], is pulled during maven `GENERATE-SOURCES` phase (the `ecs.version` property is used to retrieve the corresponding file).

The https://github.com/elastic/ecs/blob/master/generated/ecs/ecs_flat.yml[`ecs_flat.yml`] is then converted, during the same maven phase, to a java enum, using the freemarker template link:src/main/resources/ecs_flat.ftl[`ecs_flat.ftl`].

Finally, the generated file is compiled and packaged.

.Extract from ecs_flat.yml
[source,yml]
----
'@timestamp':
  dashed_name: timestamp
  description: 'Date/time when the event originated.
    This is the date/time extracted from the event, typically representing when the
    event was generated by the source.
    If the event source has no original timestamp, this value is typically populated
    by the first time the event was received by the pipeline.
    Required field for all events.'
  example: '2016-05-23T08:05:34.853Z'
  flat_name: '@timestamp'
  level: core
  name: '@timestamp'
  normalize: []
  required: true
  short: Date/time when the event originated.
  type: date
agent.build.original:
  beta: Note the usage of `wildcard` type is considered beta. This field used to be
    type `keyword`.
  dashed_name: agent-build-original
  description: 'Extended build information for the agent.
    This field is intended to contain any build information that a data source may
    provide, no specific formatting is required.'
  example: metricbeat version 7.6.0 (amd64), libbeat 7.6.0 [6a23e8f8f30f5001ba344e4e54d8d9cb82cb107c
    built 2020-02-05 23:10:10 +0000 UTC]
  flat_name: agent.build.original
  level: core
  name: build.original
  normalize: []
  short: Extended build information for the agent.
  type: wildcard
----

.ecs_flat.ftl
[source,ftl]
----
include::src/main/resources/ecs_flat.ftl[]
----

.Extract from generated EcsFields.java
[source,java]
----
package org.talend.daikon.logging.ecs;


/**
* Enumeration of all ECS fields based on ecs_flat.yaml file
*/
public enum EcsFields {
    /**
    * Date/time when the event originated.
    * Type: date
    * Example: 2016-05-23T08:05:34.853Z
    */
    _TIMESTAMP("@timestamp"),
    /**
    * Extended build information for the agent.
    * Type: keyword
    * Example: metricbeat version 7.6.0 (amd64), libbeat 7.6.0 [6a23e8f8f30f5001ba344e4e54d8d9cb82cb107c built 2020-02-05 23:10:10 +0000 UTC]
    */
    AGENT_BUILD_ORIGINAL("agent.build.original"),
    // [...]
}
----

=== MDC to ECS mapping

The goal of the layouts introduced above is to produce logs 100% ECS compatible.
For that purpose, the process illustrated below is followed during log generation :

image:https://lucid.app/publicSegments/view/8ad109dc-50a1-4be1-abfd-5033ccf91ea2/image.png[link="https://lucid.app/publicSegments/view/8ad109dc-50a1-4be1-abfd-5033ccf91ea2/image.png"]

Some custom MDC keys are defined in the file link:src/main/java/org/talend/daikon/logging/event/field/MdcKeys.java[`MdcKeys.java`].

The first step of this process is to map MDC keys with corresponding ECS fields,
by leveraging the file link:src/main/resources/mdc_ecs_mapping.properties[`mdc_ecs_mapping.properties`].

A field not referenced in this file is mapped to itself.

.mdc_ecs_mapping.properties
[source,properties]
----
include::src/main/resources/mdc_ecs_mapping.properties[]
----

CAUTION: The file link:src/main/resources/mdc_ecs_mapping.properties[`mdc_ecs_mapping.properties`] references all the available non ECS fields.
All other non ECS fields will be filtered out during next step.

=== Custom ECS fields

ECS spec explicitly allows for customization, since it cannot cover all possible use cases.

To achieve this, while also ensuring standartization of logging across all apps and services, Daikon maintains a link:src/main/resources/custom_flat.yml[list of custom fields]. The format of the file is the same as ecs_flat.yml.

=== ECS fields filtering

During this step, all non standard or custom ECS fields are removed.
For that purpose, enums `EcsFields.java` and `CustomFields.java` generated during maven `GENERATE-SOURCES` phase is leveraged.

NOTE: Fields started by `labels.` or `container.labels.` are considered as being ECS fields (see https://www.elastic.co/guide/en/ecs/master/ecs-custom-fields-in-ecs.html#_the_labels_field[Elastic doc]).

CAUTION: Once mapping step completed. All the MDC or additional field keys not present in this document won't be part of the generated log.

== Markers

The slf4j markers are added as tags:

.Example of log with markers
[source,json]
----
{
  "@timestamp": "2020-12-23T21:33:53.372Z",
  "ecs.version": "1.2.0",
  "tags": [
    "marker1",
    "marker2"
  ],
  "log.level": "DEBUG",
  "log.logger": "org.talend.daikon.logging.layout.LogBackJSONLayoutTest",
  "message": "Test Message",
  "process.thread.name": "main",
  "host.ip": [
    "10.33.225.8"
  ],
  "host.hostname": "TLND-JHERVY",
  "event.id": "5e3e35bd-0f59-49a6-8460-45da1420a9db"
}
----

The custom markers following pattern `key:value` are managed as additional fields. If the `key` is not an ECS field nor mapped to an ECS field, it is added as label:

.Example of log with custom markers
[source,json]
----
{
  "@timestamp": "2020-12-23T21:33:53.372Z",
  "ecs.version": "1.2.0",
  "tags": [
    "ecs.key:value1",
    "not_ecs_key:value2"
  ],
  "labels.not_ecs_key": "value2",
  "ecs.key": "value1",
  "log.level": "DEBUG",
  "log.logger": "org.talend.daikon.logging.layout.LogBackJSONLayoutTest",
  "message": "Test Message",
  "process.thread.name": "main",
  "host.ip": [
    "10.33.225.8"
  ],
  "host.hostname": "TLND-JHERVY",
  "event.id": "5e3e35bd-0f59-49a6-8460-45da1420a9db"
}
----

== Log correlation (Spring Cloud Sleuth)

We use https://cloud.spring.io/spring-cloud-sleuth/spring-cloud-sleuth.html[Spring Cloud Sleuth] for logs correlation, the SLF4J MDC is always set and users will immediately see the trace and span ids in logs.

By default, each entry in the Mapped Diagnostic Context (MDC) will appear as a field in the log file in the form of comma-separated "key":"value"

If you enable Spring Cloud Sleuth in your application, you will have these additional fields in your logs (once mapped by MDC/ECS mapper) :

[width="80%",cols="3,3,10",options="header"]
|===
| MDC key         | ECS field            | Description
| `X-B3-SpanId`   | `span.id`            | The id of a specific operation that took place.
| `X-B3-TraceId`  | `trace.id`           | The id of the latency graph that contains the span.
| `X-Span-Export` | `labels.span_export` | Whether the log should be exported to Zipkin or not. When would you like the span not to be exportable? In the case in which you want to wrap some operation in a Span and have it written to the logs only.
|===

=== Including Spring Cloud Sleuth in your project

Gradle style:

[source,js]
----
dependencyManagement {
    imports {
        mavenBom "org.springframework.cloud:spring-cloud-dependencies:Camden.SR4"
    }
}

dependencies {
    compile "org.springframework.cloud:spring-cloud-starter-sleuth"
}
----

Maven style:

[source,xml]
----
<dependencyManagement>
         <dependencies>
             <dependency>
                 <groupId>org.springframework.cloud</groupId>
                 <artifactId>spring-cloud-dependencies</artifactId>
                 <version>Camden.SR4</version>
                 <type>pom</type>
                 <scope>import</scope>
             </dependency>
         </dependencies>
   </dependencyManagement>

   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-sleuth</artifactId>
   </dependency>
----

== Tracking user activity ids using Slf4j

The objectives are as follows:

1. Ensure that a correlation id is assigned for each transaction (will be generated if not on service request).
If it's on service request then please use this key name: HEADER_REQUEST_CORRELATION_ID provided in MdcKeys.java

2. Ensure that the correlation id is documented on all log messages so that it can be correlated across services.

=== Filter configuration
To enable tracking user activity ids in the logs you have to :

1. Configure the Filter in your application

 a. SPA:
+
Add FilterRegistrationBean bean in your Application.java or Configuration class as this:
+
[source,java]
----
@Bean
public FilterRegistrationBean correlationHeaderFilter() {
    FilterRegistrationBean filterRegBean = new FilterRegistrationBean();
    filterRegBean.setFilter(new RequestUserActivityFilter());
    filterRegBean.setUrlPatterns(Arrays.asList("/*"));
    filterRegBean.setEnabled(Boolean.TRUE);
    filterRegBean.setName("Log Correlation Filter");
    filterRegBean.setAsyncSupported(Boolean.TRUE);
    return filterRegBean;
}
----

 b. For RESTful or SOAP service requests, this is accomplished by servlet filter.
+
In your web.xml, filter configuration is as follows:
+
[source,xml]
----
<filter>
    <filter-name>correlationIdFilter</filter-name>
        <filter-class>org.talend.daikon.logging.user.RequestUserActivityFilter</filter-class>
    </filter>

    <filter-mapping>
        <url-pattern>/*</url-pattern>
    </filter-mapping>
</filter>
----

2. Configure your log4j/logback configuration

== JSON: Dotted keys vs nested keys

For performance and readability reasons well described in https://github.com/elastic/ecs-logging-java/issues/51[this thread], the library can't guarantee that all fields are nested.

However, as Elasticsearch automatically creates nested documents if a key contains a dot, it doesn't impact log analysis.
