= Logback and Log4j2 JSON layout (ECS compatible)
:toc:
:toclevels: 3
:toc-placement!:

toc::[]

Provides http://logback.qos.ch/[Logback] & https://logging.apache.org/log4j/2.x/[Log4j2] layouts to log in https://www.json.org/json-en.html[JSON] format following https://www.elastic.co/guide/en/ecs/current/ecs-reference.html[ECS] specification.

This library leverages the https://github.com/elastic/ecs-logging-java[`ecs-logging-java`] core library powered by Elastic.

NOTE: log4j framework being outdated, its support has been removed.

== Get started

=== Add the dependency

Gradle style:

[source,js]
----
compile ("org.talend.daikon:logging-event-layout:LATEST")
----

Maven style:

[source,xml]
----
<dependency>
  	<groupId>org.talend.daikon</groupId>
  	<artifactId>logging-event-layout</artifactId>
  	<version>LATEST</version>
</dependency>
----

=== Use the ECS layout

To log using JSON format following ECS specification, you must configure logback or log4j2 to use the provided layouts.

These layouts can generally be used by any logback and log4j2 appender.

==== Logback configuration

.logback.xml
[source,xml]
----
<configuration>
    <appender name="Console" class="ch.qos.logback.core.ConsoleAppender">
        <layout class="org.talend.daikon.logging.event.layout.LogbackJSONLayout">
            <serviceName>logging-sample</serviceName>
            <locationInfo>true</locationInfo>
            <hostInfo>true</hostInfo>
            <additionalField>
                <key>labels.my_custom_label</key>
                <value>Custom value</value>
            </additionalField>
        </layout>
    </appender>
    <root level="INFO">
        <appender-ref ref="Console" />
    </root>
</configuration>
----

===== Parameters

[width="80%",cols="3,2,2,10",options="header"]
|===
| Name           | Type    | Default | Description
| `serviceName`  | String  |         | Sets the `service.name` ECS field.
| `locationInfo` | boolean | `false` | If `true`, includes the `log.origin.file.name`, `log.origin.file.line` and `log.origin.function` ECS fields.
| `hostInfo`     | boolean | `true`  | If `true`, includes the `host.ip` and `host.hostname` ECS fields.
| `addEventUuid` | boolean | `true`  | If `true`, includes the `event.id` ECS field.
|===

===== Additional fields

To include any custom field in the output, use the following syntax :

[source,xml]
----
<layout class="org.talend.daikon.logging.event.layout.LogbackJSONLayout">
    <additionalField>
        <key>key1</key>
        <value>value1</value>
    </additionalField>
    <additionalField>
        <key>key2</key>
        <value>value2</value>
    </additionalField>
</layout>
----

==== Log4j2 configuration

.log4j2.xml
[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<configuration status="INFO" packages="org.talend.daikon.logging.event.layout" verbose="false">
    <appenders>
        <Console name="Console" target="SYSTEM_OUT">
            <Log4j2ECSLayout serviceName="logging-sample" locationInfo="true" hostInfo="true">
                <KeyValuePair key="labels.my_custom_label" value="Custom value"/>
            </Log4j2ECSLayout>
        </Console>
    </appenders>
    <loggers>
        <root level="INFO">
            <appender-ref ref="Console"/>
        </root>
    </loggers>
</configuration>
----

===== Parameters

[width="80%",cols="3,2,2,10",options="header"]
|===
| Name           | Type    | Default | Description
| `serviceName`  | String  |         | Sets the `service.name` ECS field.
| `locationInfo` | boolean | `false` | If `true`, includes the `log.origin.file.name`, `log.origin.file.line` and `log.origin.function` ECS fields.
| `hostInfo`     | boolean | `true`  | If `true`, includes the `host.ip` and `host.hostname` ECS fields.
| `addEventUuid` | boolean | `true`  | If `true`, includes the `event.id` ECS field.
|===

===== Additional fields

To include any custom field in the output, use the following syntax :

[source,xml]
----
<Log4j2ECSLayout>
    <KeyValuePair key="key1" value="value1"/>
    <KeyValuePair key="key2" value="value2"/>
</Log4j2ECSLayout>
----

== MDC & additional fields

The goal of the layouts introduced above is to produce logs 100% ECS compatible.
For that purpose, the process illustrated below is followed during log generation :

image:https://lucid.app/publicSegments/view/8ad109dc-50a1-4be1-abfd-5033ccf91ea2/image.png[link="https://lucid.app/publicSegments/view/8ad109dc-50a1-4be1-abfd-5033ccf91ea2/image.png"]

=== MDC to ECS mapping

Some custom MDC keys are defined in the file link:src/main/java/org/talend/daikon/logging/event/field/MdcKeys.java[`MdcKeys.java`].

The first step of this process is to map MDC keys with corresponding ECS fields,
by leveraging the file link:src/main/resources/mdc_ecs_mapping.yml[`mdc_ecs_mapping.yml`].

A field not referenced in this file is mapped to itself.

.mdc_ecs_mapping.yml
[source,yaml]
----
include::src/main/resources/mdc_ecs_mapping.yml[]
----

CAUTION: The file link:src/main/resources/mdc_ecs_mapping.yml[`mdc_ecs_mapping.yml`] references all the available non ECS fields.
All other non ECS fields will be filtered out during next step.

=== ECS fields filtering

During this step, all non ECS fields are removed.
For that purpose, the file link:src/main/resources/ecs_flat.yml[`ecs_flat.yml`] https://github.com/elastic/ecs/blob/master/generated/ecs/ecs_flat.yml[provided by Elastic] is leveraged.

.Extract from ecs_flat.yml
[source,yaml]
----
'@timestamp':
  dashed_name: timestamp
  description: 'Date/time when the event originated.

    This is the date/time extracted from the event, typically representing when the
    event was generated by the source.

    If the event source has no original timestamp, this value is typically populated
    by the first time the event was received by the pipeline.

    Required field for all events.'
  example: '2016-05-23T08:05:34.853Z'
  flat_name: '@timestamp'
  level: core
  name: '@timestamp'
  normalize: []
  required: true
  short: Date/time when the event originated.
  type: date
ecs.version:
  dashed_name: ecs-version
  description: 'ECS version this event conforms to. `ecs.version` is a required field
    and must exist in all events.

    When querying across multiple indices -- which may conform to slightly different
    ECS versions -- this field lets integrations adjust to the schema version of the
    events.'
  example: 1.0.0
  flat_name: ecs.version
  ignore_above: 1024
  level: core
  name: version
  normalize: []
  required: true
  short: ECS version this event conforms to.
  type: keyword
----

NOTE: Fields started by `labels.` are considered as being ECS fields (see https://www.elastic.co/guide/en/ecs/master/ecs-custom-fields-in-ecs.html#_the_labels_field[Elastic doc]).

CAUTION: Once mapping step completed. All the MDC or additional field keys not present in this document won't be part of the generated log.

=== How to use ECS fields

ECS fields reference are well described in the https://www.elastic.co/guide/en/ecs/current/ecs-field-reference.html[Elastic documentation].

In order to help the developer to look for an ECS field, the file `EcsFields.java`, referencing each ECS field as constant, is generating during maven `generation-sources` phase, leveraging the file link:src/main/resources/ecs_flat.yml[`ecs_flat.yml`] and the freemarker template link:src/main/resources/ecs_flat.ftl[`ecs_flat.ftl`].

The generated file is then compiled and packaged.

.ecs_flat.ftl
[source,ftl]
----
include::src/main/resources/ecs_flat.ftl[]
----

.Extract from generated EcsFields.java
[source,java]
----
package org.talend.daikon.logging.ecs;

/**
* Constants for all ECS fields based on ecs_flat.yaml file
*/
public final class EcsFields {

    /**
    * Date/time when the event originated.
    * Type: date
    */
    public static final String TIMESTAMP = "@timestamp";
    /**
    * Extended build information for the agent.
    * Type: wildcard
    */
    public static final String AGENT_BUILD_ORIGINAL = "agent.build.original";
    // [...]
}
----

== Markers

The slf4j markers are added as tags:

.Example of log with markers
[source,json]
----
{
  "@timestamp": "2020-12-23T21:33:53.372Z",
  "ecs.version": "1.2.0",
  "tags": [
    "marker1",
    "marker2"
  ],
  "log.level": "DEBUG",
  "log.logger": "org.talend.daikon.logging.layout.LogBackJSONLayoutTest",
  "message": "Test Message",
  "process.thread.name": "main",
  "host.ip": [
    "10.33.225.8"
  ],
  "host.hostname": "TLND-JHERVY",
  "event.id": "5e3e35bd-0f59-49a6-8460-45da1420a9db"
}
----

The custom markers following pattern `key:value` are managed as additional fields. If the `key` is not an ECS field nor mapped to an ECS field, it is added as label:

.Example of log with custom markers
[source,json]
----
{
  "@timestamp": "2020-12-23T21:33:53.372Z",
  "ecs.version": "1.2.0",
  "tags": [
    "ecs.key:value1",
    "not_ecs_key:value2"
  ],
  "labels.not_ecs_key": "value2",
  "ecs.key": "value1",
  "log.level": "DEBUG",
  "log.logger": "org.talend.daikon.logging.layout.LogBackJSONLayoutTest",
  "message": "Test Message",
  "process.thread.name": "main",
  "host.ip": [
    "10.33.225.8"
  ],
  "host.hostname": "TLND-JHERVY",
  "event.id": "5e3e35bd-0f59-49a6-8460-45da1420a9db"
}
----

== Log correlation (Spring Cloud Sleuth)

We use https://cloud.spring.io/spring-cloud-sleuth/spring-cloud-sleuth.html[Spring Cloud Sleuth] for logs correlation, the SLF4J MDC is always set and users will immediately see the trace and span ids in logs.

By default, each entry in the Mapped Diagnostic Context (MDC) will appear as a field in the log file in the form of comma-separated "key":"value"

If you enable Spring Cloud Sleuth in your application, you will have these additional fields in your logs (once mapped by MDC/ECS mapper) :

[width="80%",cols="3,3,10",options="header"]
|===
| MDC key         | ECS field            | Description
| `X-B3-SpanId`   | `span.id`            | The id of a specific operation that took place.
| `X-B3-TraceId`  | `trace.id`           | The id of the latency graph that contains the span.
| `X-Span-Export` | `labels.span_export` | Whether the log should be exported to Zipkin or not. When would you like the span not to be exportable? In the case in which you want to wrap some operation in a Span and have it written to the logs only.
|===

=== Including Spring Cloud Sleuth in your project

Gradle style:

[source,js]
----
dependencyManagement {
    imports {
        mavenBom "org.springframework.cloud:spring-cloud-dependencies:Camden.SR4"
    }
}

dependencies {
    compile "org.springframework.cloud:spring-cloud-starter-sleuth"
}
----

Maven style:

[source,xml]
----
<dependencyManagement>
         <dependencies>
             <dependency>
                 <groupId>org.springframework.cloud</groupId>
                 <artifactId>spring-cloud-dependencies</artifactId>
                 <version>Camden.SR4</version>
                 <type>pom</type>
                 <scope>import</scope>
             </dependency>
         </dependencies>
   </dependencyManagement>

   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-sleuth</artifactId>
   </dependency>
----

== Tracking user activity ids using Slf4j

The objectives are as follows:

1. Ensure that a correlation id is assigned for each transaction (will be generated if not on service request).
If it's on service request then please use this key name: HEADER_REQUEST_CORRELATION_ID provided in MdcKeys.java

2. Ensure that the correlation id is documented on all log messages so that it can be correlated across services.

=== Filter configuration
To enable tracking user activity ids in the logs you have to :

1. Configure the Filter in your application

 a. SPA:
+
Add FilterRegistrationBean bean in your Application.java or Configuration class as this:
+
[source,java]
----
@Bean
public FilterRegistrationBean correlationHeaderFilter() {
    FilterRegistrationBean filterRegBean = new FilterRegistrationBean();
    filterRegBean.setFilter(new RequestUserActivityFilter());
    filterRegBean.setUrlPatterns(Arrays.asList("/*"));
    filterRegBean.setEnabled(Boolean.TRUE);
    filterRegBean.setName("Log Correlation Filter");
    filterRegBean.setAsyncSupported(Boolean.TRUE);
    return filterRegBean;
}
----

 b. For RESTful or SOAP service requests, this is accomplished by servlet filter.
+
In your web.xml, filter configuration is as follows:
+
[source,xml]
----
<filter>
    <filter-name>correlationIdFilter</filter-name>
        <filter-class>org.talend.daikon.logging.user.RequestUserActivityFilter</filter-class>
    </filter>

    <filter-mapping>
        <url-pattern>/*</url-pattern>
    </filter-mapping>
</filter>
----

2. Configure your log4j/logback configuration

== JSON: Dotted keys vs nested keys

For performance and readability reasons well described in https://github.com/elastic/ecs-logging-java/issues/51[this thread], the library can't guarantee that all fields are nested.

However, as Elasticsearch automatically creates nested documents if a key contains a dot, it doesn't impact log analysis.
